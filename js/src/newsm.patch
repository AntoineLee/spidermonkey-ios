Only in .: -L
Only in .: -R
Only in .: .deps
Only in .: ArgumentsObject.o
Only in .: BytecodeCompiler.o
Only in .: BytecodeEmitter.o
Only in .: Debugger.o
Only in .: Eval.o
Only in .: ExecutableAllocator.o
Only in .: ExecutableAllocatorPosix.o
Only in .: FoldConstants.o
Only in .: GlobalObject.o
Only in .: HashFunctions.o
Only in .: LifoAlloc.o
Only in .: Makefile
diff -aur /Users/cat/Downloads/origsm/js/src/Makefile.in ./Makefile.in
--- /Users/cat/Downloads/origsm/js/src/Makefile.in	2012-11-07 11:54:41.000000000 -0800
+++ ./Makefile.in	2012-11-12 16:34:04.000000000 -0800
@@ -407,32 +407,32 @@
            $(NONE)
 endif
 
-ifneq (,$(filter arm% sparc %86 x86_64 mips%,$(TARGET_CPU)))
-ENABLE_YARR_JIT = 1
-DEFINES += -DENABLE_YARR_JIT=1
-
-VPATH += 	$(srcdir)/assembler/assembler \
-		$(srcdir)/methodjit \
-		$(NONE)
-
-CPPSRCS +=	ARMAssembler.cpp \
-		MacroAssemblerARM.cpp \
-		MacroAssemblerX86Common.cpp \
-		YarrJIT.cpp \
-		$(NONE)
-
-ifeq (86, $(findstring 86,$(TARGET_CPU)))
-ifeq (x86_64, $(TARGET_CPU))
-#CPPSRCS		+= only_on_x86_64.cpp
-else
-#CPPSRCS		+= only_on_x86.cpp
-endif
-endif
-ifeq (arm, $(findstring arm, $(TARGET_CPU)))
-#CPPSRCS		+= only_on_arm.cpp
-endif
-
-endif
+#ifneq (,$(filter arm% sparc %86 x86_64 mips%,$(TARGET_CPU)))
+#ENABLE_YARR_JIT = 1
+#DEFINES += -DENABLE_YARR_JIT=1
+#
+#VPATH += 	$(srcdir)/assembler/assembler \
+#		$(srcdir)/methodjit \
+#		$(NONE)
+#
+#CPPSRCS +=	ARMAssembler.cpp \
+#		MacroAssemblerARM.cpp \
+#		MacroAssemblerX86Common.cpp \
+#		YarrJIT.cpp \
+#		$(NONE)
+#
+#ifeq (86, $(findstring 86,$(TARGET_CPU)))
+#ifeq (x86_64, $(TARGET_CPU))
+##CPPSRCS		+= only_on_x86_64.cpp
+#else
+##CPPSRCS		+= only_on_x86.cpp
+#endif
+#endif
+#ifeq (arm, $(findstring arm, $(TARGET_CPU)))
+##CPPSRCS		+= only_on_arm.cpp
+#endif
+#
+#endif
 
 #
 # END enclude sources for the Nitro assembler
Only in .: MapObject.o
Only in .: Marking.o
Only in .: Memory.o
Only in .: NameFunctions.o
Only in .: OSAllocatorPosix.o
Only in .: ObjectImpl.o
Only in .: PageBlock.o
Only in .: ParallelArray.o
Only in .: ParseMaps.o
Only in .: ParseNode.o
Only in .: Parser.o
Only in .: Profilers.o
Only in .: RegExp.o
Only in .: RegExpObject.o
Only in .: RegExpStatics.o
Only in .: SHA1.o
Only in .: SPSProfiler.o
Only in .: ScopeObject.o
Only in .: Stack.o
Only in .: Statistics.o
Only in .: StoreBuffer.o
Only in .: String.o
Only in .: StringBuffer.o
Only in .: TestingFunctions.o
Only in .: TokenStream.o
Only in .: Unicode.o
Only in .: Xdr.o
Only in .: YarrCanonicalizeUCS2.o
Only in .: YarrInterpreter.o
Only in .: YarrPattern.o
Only in .: YarrSyntaxChecker.o
Only in .: bignum-dtoa.o
Only in .: bignum.o
Only in ./build: ConfigStatus.pyc
Only in .: build.sh
Only in ./builtin: js2c.pyc
Only in ./builtin: jsmin.pyc
Only in .: cached-powers.o
Only in ./config: Expression.pyc
Only in ./config: Makefile
Only in ./config: Preprocessor.pyc
Only in ./config: autoconf.mk
Only in ./config: expandlibs.pyc
Only in ./config: expandlibs_config.py
Only in ./config: expandlibs_config.pyc
Only in ./config: host_nsinstall.o
Only in ./config: host_pathsub.o
Only in ./config: nsinstall
Only in ./config: nsinstall_real
Only in .: config.cache
Only in .: config.log
Only in .: config.status
Only in .: copy_headers
Only in .: cp
Only in .: dist
Only in .: diy-fp.o
Only in .: double-conversion.o
Only in ./editline: .deps
Only in ./editline: Makefile
Only in ./editline: editline.o
Only in ./editline: libeditline.a.desc
Only in ./editline: sysunix.o
Only in .: fast-dtoa.o
Only in .: fixed-dtoa.o
Only in .: host_jskwgen
Only in .: host_jskwgen.o
Only in .: host_jsoplengen
Only in .: host_jsoplengen.o
Only in .: js
Only in .: js-confdefs.h
Only in .: js-config
Only in .: js-config.h
Only in .: jsalloc.o
Only in .: jsanalyze.o
Only in ./jsapi-tests: Makefile
diff -aur /Users/cat/Downloads/origsm/js/src/jsapi.h ./jsapi.h
--- /Users/cat/Downloads/origsm/js/src/jsapi.h	2012-11-07 11:54:41.000000000 -0800
+++ ./jsapi.h	2012-11-17 01:04:54.000000000 -0800
@@ -2609,13 +2609,14 @@
 JS_ALWAYS_INLINE bool
 ToNumber(JSContext *cx, const Value &v, double *out)
 {
-    AssertCanGC();
+    // TODO: This might break something.  Check it out! -cat
+/*    AssertCanGC();
     AssertArgumentsAreSane(cx, v);
     {
         js::SkipRoot root(cx, &v);
         js::MaybeCheckStackRoots(cx);
     }
-
+*/
     if (v.isNumber()) {
         *out = v.toNumber();
         return true;
@@ -2702,13 +2703,13 @@
 JS_ALWAYS_INLINE bool
 ToUint16(JSContext *cx, const js::Value &v, uint16_t *out)
 {
-    AssertCanGC();
+/*    AssertCanGC();
     AssertArgumentsAreSane(cx, v);
     {
         js::SkipRoot skip(cx, &v);
         js::MaybeCheckStackRoots(cx);
     }
-
+*/
     if (v.isInt32()) {
         *out = uint16_t(v.toInt32());
         return true;
@@ -2719,13 +2720,13 @@
 JS_ALWAYS_INLINE bool
 ToInt32(JSContext *cx, const js::Value &v, int32_t *out)
 {
-    AssertCanGC();
+/*    AssertCanGC();
     AssertArgumentsAreSane(cx, v);
     {
         js::SkipRoot root(cx, &v);
         js::MaybeCheckStackRoots(cx);
     }
-
+*/
     if (v.isInt32()) {
         *out = v.toInt32();
         return true;
@@ -2736,13 +2737,13 @@
 JS_ALWAYS_INLINE bool
 ToUint32(JSContext *cx, const js::Value &v, uint32_t *out)
 {
-    AssertCanGC();
+/*    AssertCanGC();
     AssertArgumentsAreSane(cx, v);
     {
         js::SkipRoot root(cx, &v);
         js::MaybeCheckStackRoots(cx);
     }
-
+*/
     if (v.isInt32()) {
         *out = uint32_t(v.toInt32());
         return true;
@@ -2753,13 +2754,13 @@
 JS_ALWAYS_INLINE bool
 ToInt64(JSContext *cx, const js::Value &v, int64_t *out)
 {
-    AssertCanGC();
+/*    AssertCanGC();
     AssertArgumentsAreSane(cx, v);
     {
         js::SkipRoot skip(cx, &v);
         js::MaybeCheckStackRoots(cx);
     }
-
+*/
     if (v.isInt32()) {
         *out = int64_t(v.toInt32());
         return true;
@@ -2771,13 +2772,13 @@
 JS_ALWAYS_INLINE bool
 ToUint64(JSContext *cx, const js::Value &v, uint64_t *out)
 {
-    AssertCanGC();
+/*    AssertCanGC();
     AssertArgumentsAreSane(cx, v);
     {
         js::SkipRoot skip(cx, &v);
         js::MaybeCheckStackRoots(cx);
     }
-
+*/
     if (v.isInt32()) {
         /* Account for sign extension of negatives into the longer 64bit space. */
         *out = uint64_t(int64_t(v.toInt32()));
Only in .: jsapi.o
Only in .: jsapi.o-070b7a87
Only in .: jsapi.o-51280a8c
Only in .: jsapi.o-75e798aa
Only in .: jsapi.o-7e2418c5
Only in .: jsapi.o-83528e4e
Only in .: jsapi.o-944a2581
Only in .: jsapi.o-b44e1fba
Only in .: jsapi.o-bd7ed71a
Only in .: jsapi.o-ca41682d
Only in .: jsapi.o-cd16d954
Only in .: jsapi.o-df5f9d1f
Only in .: jsapi.o-f20a7960
diff -aur /Users/cat/Downloads/origsm/js/src/jsarray.cpp ./jsarray.cpp
--- /Users/cat/Downloads/origsm/js/src/jsarray.cpp	2012-11-07 11:54:41.000000000 -0800
+++ ./jsarray.cpp	2012-11-19 14:32:42.000000000 -0800
@@ -1219,6 +1219,40 @@
         NULL,       /* iteratorObject  */
         NULL,       /* unused      */
         false,      /* isWrappedNative */
+    },
+    {
+        array_lookupGeneric,
+        array_lookupProperty,
+        array_lookupElement,
+        array_lookupSpecial,
+        array_defineGeneric,
+        array_defineProperty,
+        array_defineElement,
+        array_defineSpecial,
+        array_getGeneric,
+        array_getProperty,
+        array_getElement,
+        NULL, /* getElementIfPresent, because this is hard for now for
+                 slow arrays */
+        array_getSpecial,
+        array_setGeneric,
+        array_setProperty,
+        array_setElement,
+        array_setSpecial,
+        array_getGenericAttributes,
+        array_getPropertyAttributes,
+        array_getElementAttributes,
+        array_getSpecialAttributes,
+        array_setGenericAttributes,
+        array_setPropertyAttributes,
+        array_setElementAttributes,
+        array_setSpecialAttributes,
+        array_deleteProperty,
+        array_deleteElement,
+        array_deleteSpecial,
+        NULL,       /* enumerate      */
+        NULL,       /* typeOf         */
+        NULL,       /* thisObject     */
     }
 };
 
Only in .: jsarray.o
Only in .: jsarray.o-0d3794c0
Only in .: jsarray.o-a397ea0d
Only in .: jsarray.o-a4da864e
Only in .: jsarray.o-a97efbfd
Only in .: jsarray.o-b030de68
Only in .: jsarray.o-c6a28ef5
Only in .: jsatom.o
Only in .: jsautokw.h
Only in .: jsautooplen.h
Only in .: jsbool.o
Only in .: jsclone.o
diff -aur /Users/cat/Downloads/origsm/js/src/jscntxt.cpp ./jscntxt.cpp
--- /Users/cat/Downloads/origsm/js/src/jscntxt.cpp	2012-11-07 11:54:41.000000000 -0800
+++ ./jscntxt.cpp	2012-11-12 16:34:08.000000000 -0800
@@ -1339,7 +1339,9 @@
     functionCallback(NULL),
 #endif
     enumerators(NULL),
+#if JS_HAS_GENERATORS
     innermostGenerator_(NULL),
+#endif
 #ifdef DEBUG
     stackIterAssertionEnabled(true),
 #endif
@@ -1377,6 +1379,8 @@
 }
 
 
+#if JS_HAS_GENERATORS
+
 void
 JSContext::enterGenerator(JSGenerator *gen)
 {
@@ -1393,6 +1397,8 @@
     gen->prevGenerator = NULL;
 }
 
+#endif
+
 
 bool
 JSContext::runningWithTrustedPrincipals() const
diff -aur /Users/cat/Downloads/origsm/js/src/jscntxt.h ./jscntxt.h
--- /Users/cat/Downloads/origsm/js/src/jscntxt.h	2012-11-07 11:54:41.000000000 -0800
+++ ./jscntxt.h	2012-11-12 16:34:08.000000000 -0800
@@ -1557,6 +1557,7 @@
     /* List of currently active non-escaping enumerators (for-in). */
     js::PropertyIteratorObject *enumerators;
 
+#if JS_HAS_GENERATORS
   private:
     /* Innermost-executing generator or null if no generator are executing. */
     JSGenerator *innermostGenerator_;
@@ -1564,6 +1565,8 @@
     JSGenerator *innermostGenerator() const { return innermostGenerator_; }
     void enterGenerator(JSGenerator *gen);
     void leaveGenerator(JSGenerator *gen);
+#endif
+  public:
 
     inline void* malloc_(size_t bytes) {
         return runtime->malloc_(bytes, this);
Only in .: jscntxt.o
Only in .: jscompartment.o
Only in .: jscrashreport.o
Only in .: jsdate.o
Only in .: jsdbgapi.o
Only in .: jsdhash.o
Only in .: jsdtoa.o
Only in .: jsexn.o
Only in .: jsfriendapi.o
Only in .: jsfun.o
Only in .: jsgc.o
Only in .: jsinfer.o
diff -aur /Users/cat/Downloads/origsm/js/src/jsinterp.cpp ./jsinterp.cpp
--- /Users/cat/Downloads/origsm/js/src/jsinterp.cpp	2012-11-07 11:54:41.000000000 -0800
+++ ./jsinterp.cpp	2012-11-19 11:33:31.000000000 -0800
@@ -267,7 +267,9 @@
     JS_ASSERT(script);
     JS_ASSERT(fp == cx->fp());
     JS_ASSERT(fp->script() == script);
+#if JS_HAS_GENERATORS
     JS_ASSERT_IF(!fp->isGeneratorFrame(), cx->regs().pc == script->code);
+#endif
     JS_ASSERT_IF(fp->isEvalFrame(), script->isActiveEval);
 #ifdef JS_METHODJIT_SPEW
     JMCheckLogging();
@@ -285,7 +287,9 @@
         {}
         ~CheckStackBalance() {
             JS_ASSERT(fp == cx->fp());
+#if JS_HAS_GENERATORS
             JS_ASSERT_IF(!fp->isGeneratorFrame(), enumerators == cx->enumerators);
+#endif
         }
     } check(cx);
 #endif
@@ -1025,7 +1029,6 @@
 
 # define DO_OP()            goto do_op
 # define DO_NEXT_OP(n)      JS_BEGIN_MACRO                                    \
-                                JS_ASSERT((n) == len);                        \
                                 goto advance_pc;                              \
                             JS_END_MACRO
 
@@ -1175,12 +1178,16 @@
     /* Don't call the script prologue if executing between Method and Trace JIT. */
     if (interpMode == JSINTERP_NORMAL) {
         StackFrame *fp = regs.fp();
+#if JS_HAS_GENERATORS
         if (!fp->isGeneratorFrame()) {
+#endif
             if (!fp->prologue(cx, UseNewTypeAtEntry(cx, fp)))
                 goto error;
+#if JS_HAS_GENERATORS
         } else {
             Probes::enterScript(cx, script, script->function(), fp);
         }
+#endif
         if (cx->compartment->debugMode()) {
             JSTrapStatus status = ScriptDebugPrologue(cx, fp);
             switch (status) {
Only in .: jsinterp.o
Only in .: jsiter.o
Only in .: jslog2.o
Only in .: jsmath.o
Only in .: jsmemorymetrics.o
Only in .: jsnativestack.o
Only in .: jsnum.o
diff -aur /Users/cat/Downloads/origsm/js/src/jsobj.cpp ./jsobj.cpp
--- /Users/cat/Downloads/origsm/js/src/jsobj.cpp	2012-11-07 11:54:41.000000000 -0800
+++ ./jsobj.cpp	2012-11-19 14:26:03.000000000 -0800
@@ -5525,8 +5525,10 @@
             fprintf(stderr, " eval");
         if (!i.isIon() && i.interpFrame()->isYielding())
             fprintf(stderr, " yielding");
+#if JS_HAS_GENERATORS
         if (!i.isIon() && i.interpFrame()->isGeneratorFrame())
             fprintf(stderr, " generator");
+#endif
         fputc('\n', stderr);
 
         fprintf(stderr, "  scopeChain: (JSObject *) %p\n", (void *) i.scopeChain());
Only in .: jsobj.o
Only in .: json.o
Only in .: jsonparser.o
diff -aur /Users/cat/Downloads/origsm/js/src/jsopcode.cpp ./jsopcode.cpp
--- /Users/cat/Downloads/origsm/js/src/jsopcode.cpp	2012-11-07 11:54:41.000000000 -0800
+++ ./jsopcode.cpp	2012-11-12 16:34:08.000000000 -0800
@@ -4839,8 +4839,11 @@
                     js_free((void *)rval);
                     break;
                 }
-#endif /* JS_HAS_GENERATOR_EXPRS */
                 else if (sn && SN_TYPE(sn) == SRC_CONTINUE) {
+#else
+                sn = js_GetSrcNote(cx, jp->script, pc);
+                if (sn && SN_TYPE(sn) == SRC_CONTINUE) {
+#endif /* JS_HAS_GENERATOR_EXPRS */
                     /*
                      * Local function definitions have a lambda;setlocal;pop
                      * triple (annotated with SRC_CONTINUE) in the function
Only in .: jsopcode.o
Only in .: jsperf.o
Only in .: jsprf.o
diff -aur /Users/cat/Downloads/origsm/js/src/jsprobes.h ./jsprobes.h
--- /Users/cat/Downloads/origsm/js/src/jsprobes.h	2012-11-07 11:54:41.000000000 -0800
+++ ./jsprobes.h	2012-11-12 16:34:08.000000000 -0800
@@ -331,7 +331,9 @@
     JSRuntime *rt = cx->runtime;
     if (rt->spsProfiler.enabled()) {
         rt->spsProfiler.enter(cx, script, maybeFun);
+#if JS_HAS_GENERATORS
         JS_ASSERT_IF(!fp->isGeneratorFrame(), !fp->hasPushedSPSFrame());
+#endif
         fp->setPushedSPSFrame();
     }
 
Only in .: jsprobes.o
Only in .: jspropertycache.o
Only in .: jspropertytree.o
Only in .: jsproxy.o
Only in .: jsreflect.o
Only in .: jsscope.o
Only in .: jsscript.o
Only in .: jsstr.o
Only in .: jstypedarray.o
Only in .: jsutil.o
diff -aur /Users/cat/Downloads/origsm/js/src/jsversion.h ./jsversion.h
--- /Users/cat/Downloads/origsm/js/src/jsversion.h	2012-11-07 11:54:41.000000000 -0800
+++ ./jsversion.h	2012-11-21 18:34:15.000000000 -0800
@@ -124,20 +124,20 @@
 
 #elif 180 <= JS_VERSION && JS_VERSION <= 185
 
-#define JS_HAS_STR_HTML_HELPERS 1       /* has str.anchor, str.bold, etc. */
+#define JS_HAS_STR_HTML_HELPERS 0       /* has str.anchor, str.bold, etc. */
 #define JS_HAS_OBJ_PROTO_PROP   1       /* has o.__proto__ etc. */
-#define JS_HAS_OBJ_WATCHPOINT   1       /* has o.watch and o.unwatch */
-#define JS_HAS_TOSOURCE         1       /* has Object/Array toSource method */
+#define JS_HAS_OBJ_WATCHPOINT   0       /* has o.watch and o.unwatch */
+#define JS_HAS_TOSOURCE         0       /* has Object/Array toSource method */
 #define JS_HAS_CATCH_GUARD      1       /* has exception handling catch guard */
-#define JS_HAS_UNEVAL           1       /* has uneval() top-level function */
+#define JS_HAS_UNEVAL           0       /* has uneval() top-level function */
 #define JS_HAS_CONST            1       /* has JS2 const as alternative var */
 #define JS_HAS_FUN_EXPR_STMT    1       /* has function expression statement */
-#define JS_HAS_NO_SUCH_METHOD   1       /* has o.__noSuchMethod__ handler */
-#define JS_HAS_GENERATORS       1       /* has yield in generator function */
-#define JS_HAS_BLOCK_SCOPE      1       /* has block scope via let/arraycomp */
-#define JS_HAS_DESTRUCTURING    2       /* has [a,b] = ... or {p:a,q:b} = ... */
-#define JS_HAS_GENERATOR_EXPRS  1       /* has (expr for (lhs in iterable)) */
-#define JS_HAS_EXPR_CLOSURES    1       /* has function (formals) listexpr */
+#define JS_HAS_NO_SUCH_METHOD   0       /* has o.__noSuchMethod__ handler */
+#define JS_HAS_GENERATORS       0       /* has yield in generator function */
+#define JS_HAS_BLOCK_SCOPE      0       /* has block scope via let/arraycomp */
+#define JS_HAS_DESTRUCTURING    0       /* has [a,b] = ... or {p:a,q:b} = ... */
+#define JS_HAS_GENERATOR_EXPRS  0       /* has (expr for (lhs in iterable)) */
+#define JS_HAS_EXPR_CLOSURES    0       /* has function (formals) listexpr */
 
 #else
 
@@ -149,7 +149,7 @@
 #define JS_HAS_NEW_GLOBAL_OBJECT        1
 
 /* Support for JS_MakeSystemObject. */
-#define JS_HAS_MAKE_SYSTEM_OBJECT       1
+#define JS_HAS_MAKE_SYSTEM_OBJECT       0
 
 /* Feature-test macro for evolving destructuring support. */
 #define JS_HAS_DESTRUCTURING_SHORTHAND  (JS_HAS_DESTRUCTURING == 2)
Only in .: jswatchpoint.o
Only in .: jsweakmap.o
Only in .: jsworkers.o
Only in .: jswrapper.o
Only in .: jsxml.o
Only in .: libjs_static.a
Only in .: libjs_static.a.desc
Only in .: libjs_static.armv7.a
Only in .: libjs_static.i386.a
Only in .: mozilla
Only in .: newsm.patch
Only in .: pm_stub.o
Only in .: prmjtime.o
Only in .: selfhosted.js
Only in .: selfhosted.out.h
Only in .: sharkctl.o
Only in ./shell: .deps
Only in ./shell: Makefile
Only in ./shell: js
Only in ./shell: js.o
Only in ./shell: jsheaptools.o
Only in ./shell: jsoptparse.o
Only in ./shell: tmpQjIErE.list
Only in .: strtod.o
Only in ./tests: Makefile
Only in .: unallmakefiles
Only in .: update_patch.sh
diff -aur /Users/cat/Downloads/origsm/js/src/vm/NumericConversions.h ./vm/NumericConversions.h
--- /Users/cat/Downloads/origsm/js/src/vm/NumericConversions.h	2012-11-21 15:58:43.000000000 -0800
+++ ./vm/NumericConversions.h	2012-11-21 20:54:53.000000000 -0800
@@ -150,138 +150,360 @@
 #endif
 }
 
-/* ES5 9.5 ToInt32 (specialized for doubles). */
-inline int32_t
-ToInt32(double dd)
-{
-#if defined (__arm__) && defined (__GNUC__)
-    float d = dd;
-    int32_t i;
-    uint32_t    tmp0;
-    uint32_t    tmp1;
-    uint32_t    tmp2;
-    uint32_t    tmp3;
-    asm (
-    // We use a pure integer solution here. In the 'softfp' ABI, the argument
-    // will start in r0 and r1, and VFP can't do all of the necessary ECMA
-    // conversions by itself so some integer code will be required anyway. A
-    // hybrid solution is faster on A9, but this pure integer solution is
-    // notably faster for A8.
-
-    // %0 is the result register, and may alias either of the %[QR]1 registers.
-    // %Q4 holds the lower part of the mantissa.
-    // %R4 holds the sign, exponent, and the upper part of the mantissa.
-    // %1, %2 and %3 are used as temporary values.
-
-    // Extract the exponent.
-"   mov     %1, %4, LSR #20\n"
-"   bic     %1, %1, #(1 << 11)\n"  // Clear the sign.
-
-    // Set the implicit top bit of the mantissa. This clobbers a bit of the
-    // exponent, but we have already extracted that.
-"   orr     %4, %4, #(1 << 20)\n"
-
-    // Special Cases
-    //   We should return zero in the following special cases:
-    //    - Exponent is 0x000 - 1023: +/-0 or subnormal.
-    //    - Exponent is 0x7ff - 1023: +/-INFINITY or NaN
-    //      - This case is implicitly handled by the standard code path anyway,
-    //        as shifting the mantissa up by the exponent will result in '0'.
-    //
-    // The result is composed of the mantissa, prepended with '1' and
-    // bit-shifted left by the (decoded) exponent. Note that because the r1[20]
-    // is the bit with value '1', r1 is effectively already shifted (left) by
-    // 20 bits, and r0 is already shifted by 52 bits.
-
-    // Adjust the exponent to remove the encoding offset. If the decoded
-    // exponent is negative, quickly bail out with '0' as such values round to
-    // zero anyway. This also catches +/-0 and subnormals.
-"   sub     %1, %1, #0xff\n"
-"   subs    %1, %1, #0x300\n"
-"   bmi     8f\n"
-
-    //  %1 = (decoded) exponent >= 0
-    //  %R4 = upper mantissa and sign
-
-    // ---- Lower Mantissa ----
-"   subs    %3, %1, #52\n"         // Calculate exp-52
-"   bmi     1f\n"
-
-    // Shift r0 left by exp-52.
-    // Ensure that we don't overflow ARM's 8-bit shift operand range.
-    // We need to handle anything up to an 11-bit value here as we know that
-    // 52 <= exp <= 1024 (0x400). Any shift beyond 31 bits results in zero
-    // anyway, so as long as we don't touch the bottom 5 bits, we can use
-    // a logical OR to push long shifts into the 32 <= (exp&0xff) <= 255 range.
-"   bic     %2, %3, #0xff\n"
-"   orr     %3, %3, %2, LSR #3\n"
-
-    // We can now perform a straight shift, avoiding the need for any
-    // conditional instructions or extra branches.
-"   mov     %5, %5, LSL %3\n"
-"   b       2f\n"
-"1:\n" // Shift r0 right by 52-exp.
-    // We know that 0 <= exp < 52, and we can shift up to 255 bits so 52-exp
-    // will always be a valid shift and we can sk%3 the range check for this case.
-"   rsb     %3, %1, #52\n"
-"   mov     %5, %5, LSR %3\n"
-
-    //  %1 = (decoded) exponent
-    //  %R4 = upper mantissa and sign
-    //  %Q4 = partially-converted integer
-
-"2:\n"
-    // ---- Upper Mantissa ----
-    // This is much the same as the lower mantissa, with a few different
-    // boundary checks and some masking to hide the exponent & sign bit in the
-    // upper word.
-    // Note that the upper mantissa is pre-shifted by 20 in %R4, but we shift
-    // it left more to remove the sign and exponent so it is effectively
-    // pre-shifted by 31 bits.
-"   subs    %3, %1, #31\n"          // Calculate exp-31
-"   mov     %1, %4, LSL #11\n"     // Re-use %1 as a temporary register.
-"   bmi     3f\n"
-
-    // Shift %R4 left by exp-31.
-    // Avoid overflowing the 8-bit shift range, as before.
-"   bic     %2, %3, #0xff\n"
-"   orr     %3, %3, %2, LSR #3\n"
-    // Perform the shift.
-"   mov     %2, %1, LSL %3\n"
-"   b       4f\n"
-"3:\n" // Shift r1 right by 31-exp.
-    // We know that 0 <= exp < 31, and we can shift up to 255 bits so 31-exp
-    // will always be a valid shift and we can skip the range check for this case.
-"   rsb     %3, %3, #0\n"          // Calculate 31-exp from -(exp-31)
-"   mov     %2, %1, LSR %3\n"      // Thumb-2 can't do "LSR %3" in "orr".
-
-    //  %Q4 = partially-converted integer (lower)
-    //  %R4 = upper mantissa and sign
-    //  %2 = partially-converted integer (upper)
-
-"4:\n"
-    // Combine the converted parts.
-"   orr     %5, %5, %2\n"
-    // Negate the result if we have to, and move it to %0 in the process. To
-    // avoid conditionals, we can do this by inverting on %R4[31], then adding
-    // %R4[31]>>31.
-"   eor     %5, %5, %4, ASR #31\n"
-"   add     %0, %5, %4, LSR #31\n"
-"   b       9f\n"
-
-"8:\n"
-    // +/-INFINITY, +/-0, subnormals, NaNs, and anything else out-of-range that
-    // will result in a conversion of '0'.
-"   mov     %0, #0\n"
-"9:\n"
-    : "=r" (i), "=&r" (tmp0), "=&r" (tmp1), "=&r" (tmp2), "=&r" (d), "=r" (tmp3)
-    : "4" (d)
-    : "cc"
-        );
-    return i;
-#else
-    return ToIntWidth<32, int32_t>(dd);
-#endif
+
+
+
+template <class Dest, class Source>
+struct BitCastHelper {
+  inline static Dest cast(const Source& source) {
+    Dest dest;
+    memcpy(&dest, &source, sizeof(dest));
+    return dest;
+  }
+};
+
+template <class Dest, class Source>
+struct BitCastHelper<Dest, Source*> {
+  inline static Dest cast(Source* source) {
+    return BitCastHelper<Dest, uintptr_t>::
+        cast(reinterpret_cast<uintptr_t>(source));
+  }
+};
+
+template <class Dest, class Source>
+inline Dest BitCast(const Source& source);
+
+template <class Dest, class Source>
+inline Dest BitCast(const Source& source) {
+  return BitCastHelper<Dest, Source>::cast(source);
+}
+
+
+
+
+// This "Do It Yourself Floating Point" class implements a floating-point number
+// with a uint64 significand and an int exponent. Normalized DiyFp numbers will
+// have the most significant bit of the significand set.
+// Multiplication and Subtraction do not normalize their results.
+// DiyFp are not designed to contain special doubles (NaN and Infinity).
+class DiyFp {
+ public:
+  static const int kSignificandSize = 64;
+
+  DiyFp() : f_(0), e_(0) {}
+  DiyFp(uint64_t f, int e) : f_(f), e_(e) {}
+
+  // this = this - other.
+  // The exponents of both numbers must be the same and the significand of this
+  // must be bigger than the significand of other.
+  // The result will not be normalized.
+  void Subtract(const DiyFp& other) {
+    f_ -= other.f_;
+  }
+
+  // Returns a - b.
+  // The exponents of both numbers must be the same and this must be bigger
+  // than other. The result will not be normalized.
+  static DiyFp Minus(const DiyFp& a, const DiyFp& b) {
+    DiyFp result = a;
+    result.Subtract(b);
+    return result;
+  }
+
+
+  // this = this * other.
+  void Multiply(const DiyFp& other);
+
+  // returns a * b;
+  static DiyFp Times(const DiyFp& a, const DiyFp& b) {
+    DiyFp result = a;
+    result.Multiply(b);
+    return result;
+  }
+
+  void Normalize() {
+    uint64_t f = f_;
+    int e = e_;
+
+    // This method is mainly called for normalizing boundaries. In general
+    // boundaries need to be shifted by 10 bits. We thus optimize for this case.
+    const uint64_t k10MSBits = static_cast<uint64_t>(0x3FF) << 54;
+    while ((f & k10MSBits) == 0) {
+      f <<= 10;
+      e -= 10;
+    }
+    while ((f & kUint64MSB) == 0) {
+      f <<= 1;
+      e--;
+    }
+    f_ = f;
+    e_ = e;
+  }
+
+  static DiyFp Normalize(const DiyFp& a) {
+    DiyFp result = a;
+    result.Normalize();
+    return result;
+  }
+
+  uint64_t f() const { return f_; }
+  int e() const { return e_; }
+
+  void set_f(uint64_t new_value) { f_ = new_value; }
+  void set_e(int new_value) { e_ = new_value; }
+
+ private:
+  static const uint64_t kUint64MSB = static_cast<uint64_t>(1) << 63;
+
+  uint64_t f_;
+  int e_;
+};
+
+
+
+
+
+
+
+
+
+// We assume that doubles and uint64_t have the same endianness.
+inline uint64_t double_to_uint64(double d) { return BitCast<uint64_t>(d); }
+inline double uint64_to_double(uint64_t d64) { return BitCast<double>(d64); }
+
+#define V8_2PART_UINT64_C(a, b) (((static_cast<uint64_t>(a) << 32) + 0x##b##u))
+
+// Helper functions for doubles.
+class Double {
+ public:
+  static const uint64_t kSignMask = V8_2PART_UINT64_C(0x80000000, 00000000);
+  static const uint64_t kExponentMask = V8_2PART_UINT64_C(0x7FF00000, 00000000);
+  static const uint64_t kSignificandMask =
+      V8_2PART_UINT64_C(0x000FFFFF, FFFFFFFF);
+  static const uint64_t kHiddenBit = V8_2PART_UINT64_C(0x00100000, 00000000);
+  static const int kPhysicalSignificandSize = 52;  // Excludes the hidden bit.
+  static const int kSignificandSize = 53;
+
+  Double() : d64_(0) {}
+  explicit Double(double d) : d64_(double_to_uint64(d)) {}
+  explicit Double(uint64_t d64) : d64_(d64) {}
+  explicit Double(DiyFp diy_fp)
+    : d64_(DiyFpToUint64(diy_fp)) {}
+
+  // The value encoded by this Double must be greater or equal to +0.0.
+  // It must not be special (infinity, or NaN).
+  DiyFp AsDiyFp() const {
+    return DiyFp(Significand(), Exponent());
+  }
+
+  // The value encoded by this Double must be strictly greater than 0.
+  DiyFp AsNormalizedDiyFp() const {
+    uint64_t f = Significand();
+    int e = Exponent();
+
+    // The current double could be a denormal.
+    while ((f & kHiddenBit) == 0) {
+      f <<= 1;
+      e--;
+    }
+    // Do the final shifts in one go.
+    f <<= DiyFp::kSignificandSize - kSignificandSize;
+    e -= DiyFp::kSignificandSize - kSignificandSize;
+    return DiyFp(f, e);
+  }
+
+  // Returns the double's bit as uint64.
+  uint64_t AsUint64() const {
+    return d64_;
+  }
+
+  // Returns the next greater double. Returns +infinity on input +infinity.
+  double NextDouble() const {
+    if (d64_ == kInfinity) return Double(kInfinity).value();
+    if (Sign() < 0 && Significand() == 0) {
+      // -0.0
+      return 0.0;
+    }
+    if (Sign() < 0) {
+      return Double(d64_ - 1).value();
+    } else {
+      return Double(d64_ + 1).value();
+    }
+  }
+
+  int Exponent() const {
+    if (IsDenormal()) return kDenormalExponent;
+
+    uint64_t d64 = AsUint64();
+    int biased_e =
+        static_cast<int>((d64 & kExponentMask) >> kPhysicalSignificandSize);
+    return biased_e - kExponentBias;
+  }
+
+  uint64_t Significand() const {
+    uint64_t d64 = AsUint64();
+    uint64_t significand = d64 & kSignificandMask;
+    if (!IsDenormal()) {
+      return significand + kHiddenBit;
+    } else {
+      return significand;
+    }
+  }
+
+  // Returns true if the double is a denormal.
+  bool IsDenormal() const {
+    uint64_t d64 = AsUint64();
+    return (d64 & kExponentMask) == 0;
+  }
+
+  // We consider denormals not to be special.
+  // Hence only Infinity and NaN are special.
+  bool IsSpecial() const {
+    uint64_t d64 = AsUint64();
+    return (d64 & kExponentMask) == kExponentMask;
+  }
+
+  bool IsInfinite() const {
+    uint64_t d64 = AsUint64();
+    return ((d64 & kExponentMask) == kExponentMask) &&
+        ((d64 & kSignificandMask) == 0);
+  }
+
+  int Sign() const {
+    uint64_t d64 = AsUint64();
+    return (d64 & kSignMask) == 0? 1: -1;
+  }
+
+  // Precondition: the value encoded by this Double must be greater or equal
+  // than +0.0.
+  DiyFp UpperBoundary() const {
+    return DiyFp(Significand() * 2 + 1, Exponent() - 1);
+  }
+
+  // Returns the two boundaries of this.
+  // The bigger boundary (m_plus) is normalized. The lower boundary has the same
+  // exponent as m_plus.
+  // Precondition: the value encoded by this Double must be greater than 0.
+  void NormalizedBoundaries(DiyFp* out_m_minus, DiyFp* out_m_plus) const {
+    DiyFp v = this->AsDiyFp();
+    bool significand_is_zero = (v.f() == kHiddenBit);
+    DiyFp m_plus = DiyFp::Normalize(DiyFp((v.f() << 1) + 1, v.e() - 1));
+    DiyFp m_minus;
+    if (significand_is_zero && v.e() != kDenormalExponent) {
+      // The boundary is closer. Think of v = 1000e10 and v- = 9999e9.
+      // Then the boundary (== (v - v-)/2) is not just at a distance of 1e9 but
+      // at a distance of 1e8.
+      // The only exception is for the smallest normal: the largest denormal is
+      // at the same distance as its successor.
+      // Note: denormals have the same exponent as the smallest normals.
+      m_minus = DiyFp((v.f() << 2) - 1, v.e() - 2);
+    } else {
+      m_minus = DiyFp((v.f() << 1) - 1, v.e() - 1);
+    }
+    m_minus.set_f(m_minus.f() << (m_minus.e() - m_plus.e()));
+    m_minus.set_e(m_plus.e());
+    *out_m_plus = m_plus;
+    *out_m_minus = m_minus;
+  }
+
+  double value() const { return uint64_to_double(d64_); }
+
+  // Returns the significand size for a given order of magnitude.
+  // If v = f*2^e with 2^p-1 <= f <= 2^p then p+e is v's order of magnitude.
+  // This function returns the number of significant binary digits v will have
+  // once its encoded into a double. In almost all cases this is equal to
+  // kSignificandSize. The only exception are denormals. They start with leading
+  // zeroes and their effective significand-size is hence smaller.
+  static int SignificandSizeForOrderOfMagnitude(int order) {
+    if (order >= (kDenormalExponent + kSignificandSize)) {
+      return kSignificandSize;
+    }
+    if (order <= kDenormalExponent) return 0;
+    return order - kDenormalExponent;
+  }
+
+ private:
+  static const int kExponentBias = 0x3FF + kPhysicalSignificandSize;
+  static const int kDenormalExponent = -kExponentBias + 1;
+  static const int kMaxExponent = 0x7FF - kExponentBias;
+  static const uint64_t kInfinity = V8_2PART_UINT64_C(0x7FF00000, 00000000);
+
+  const uint64_t d64_;
+
+  static uint64_t DiyFpToUint64(DiyFp diy_fp) {
+    uint64_t significand = diy_fp.f();
+    int exponent = diy_fp.e();
+    while (significand > kHiddenBit + kSignificandMask) {
+      significand >>= 1;
+      exponent++;
+    }
+    if (exponent >= kMaxExponent) {
+      return kInfinity;
+    }
+    if (exponent < kDenormalExponent) {
+      return 0;
+    }
+    while (exponent > kDenormalExponent && (significand & kHiddenBit) == 0) {
+      significand <<= 1;
+      exponent--;
+    }
+    uint64_t biased_exponent;
+    if (exponent == kDenormalExponent && (significand & kHiddenBit) == 0) {
+      biased_exponent = 0;
+    } else {
+      biased_exponent = static_cast<uint64_t>(exponent + kExponentBias);
+    }
+    return (significand & kSignificandMask) |
+        (biased_exponent << kPhysicalSignificandSize);
+  }
+};
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+// The fast double-to-(unsigned-)int conversion routine does not guarantee
+// rounding towards zero.
+// The result is unspecified if x is infinite or NaN, or if the rounded
+// integer value is outside the range of type int.
+inline int FastD2I(double x) {
+  // The static_cast convertion from double to int used to be slow, but
+  // as new benchmarks show, now it is much faster than lrint().
+  return static_cast<int>(x);
+}
+
+inline double FastI2D(int x) {
+  // There is no rounding involved in converting an integer to a
+  // double, so this code should compile to a few instructions without
+  // any FPU pipeline stalls.
+  return static_cast<double>(x);
+}
+
+inline int32_t ToInt32(double x) {
+  int32_t i = FastD2I(x);
+  if (FastI2D(i) == x) return i;
+  Double d(x);
+  int exponent = d.Exponent();
+  if (exponent < 0) {
+    if (exponent <= -Double::kSignificandSize) return 0;
+    return d.Sign() * static_cast<int32_t>(d.Significand() >> -exponent);
+  } else {
+    if (exponent > 31) return 0;
+    return d.Sign() * static_cast<int32_t>(d.Significand() << exponent);
+  }
 }
 
 /* ES5 9.6 (specialized for doubles). */
